{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CLNV_LjqRLG",
        "outputId": "d17d34b9-09ab-4ebf-c08c-d16aa23ca8e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForQuestionAnswering\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "gw5_gCVgrc0d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9ctEs2-Igmh",
        "outputId": "554d94e8-f83f-4786-bba4-d13835556b09"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_for_bert = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "metadata": {
        "id": "5x4bIiz-Poty"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#max_len is maximum size of passage\n",
        "def bert_question_answer(question, passage, max_len=500):\n",
        "\n",
        "    #Tokenize input question and passage\n",
        "    #Include unique tokens- [CLS] and [SEP]\n",
        "    input_ids = tokenizer_for_bert.encode(question,passage,max_length = max_len,truncation=True)\n",
        "\n",
        "    #Getting number of tokens in 1st sentence (question) and 2nd sentence (passage that contains answer)\n",
        "    sep_index = input_ids.index(102)\n",
        "    len_question = sep_index + 1\n",
        "    len_passage = len(input_ids) - len_question\n",
        "\n",
        "    tokens = tokenizer_for_bert.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "     #Converting token ids to tokens\n",
        "    segment_ids = [0]*len_question + [1]*(len_passage)\n",
        "\n",
        "    #Getting start and end scores for answer\n",
        "    #Converting input arrays to torch tensors before passing to the model\n",
        "    start_token_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))[0]\n",
        "    end_token_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))[1]\n",
        "\n",
        "    #Converting scores tensors to numpy arrays\n",
        "    start_token_scores = start_token_scores.detach().numpy().flatten()\n",
        "    end_token_scores = end_token_scores.detach().numpy().flatten()\n",
        "\n",
        "    #Getting start and end index of answer based on highest scores\n",
        "    answer_start_index = np.argmax(start_token_scores)\n",
        "    answer_end_index = np.argmax(end_token_scores)\n",
        "\n",
        "    start_token_score = np.round(start_token_scores[answer_start_index],2)\n",
        "    end_token_score = np.round(end_token_scores[answer_end_index],2)\n",
        "\n",
        "    answer = tokens[answer_start_index]\n",
        "    for i in range(answer_start_index + 1, answer_end_index + 1):\n",
        "        if tokens[i][0:2] == \"##\":\n",
        "            answer += tokens[i][2:]\n",
        "        else:\n",
        "            answer += ' ' + tokens[i]\n",
        "\n",
        "    # If the answer didn't find in the passage\n",
        "    if(answer_start_index == 0) or (start_token_score < 0) or (answer == '[SEP]') or (answer_end_index < answer_start_index):\n",
        "        answer = \"Sorry!,I could not find an answer in passage.\"\n",
        "    return(answer_start_index,answer_end_index,start_token_score,end_token_score,answer)\n",
        "\n",
        "#Testing function\n",
        "bert_question_answer(\"What is my name\",\"Hello, I am Ishwar. My friend name is Ajay. He is the son of Kristen. I spend most of the time with Ajay.He always call me by my nick name. Ajay call me programmer. Except Ajay, my other friend call me by my original name. Bijay is also my friend.\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkCvP57xQLkd",
        "outputId": "26381d3c-5d76-4a9f-e505-bc714115d0e4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 12, 3.89, 4.91, 'ishwar')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "passage = \"Cricket, England’s national summer sport, which is now played throughout the world, particularly in Australia, India, Pakistan, the West Indies, and the British Isles.Cricket is played with a bat and ball and involves two competing sides (teams) of 11 players. The field is oval with a rectangular area in the middle, known as the pitch, that is 22 yards (20.12 metres) by 10 feet (3.04 metres) wide. Two sets of three sticks, called wickets, are set in the ground at each end of the pitch. Across the top of each wicket lie horizontal pieces called bails. The sides take turns at batting and bowling (pitching); each turn is called an “innings” (always plural). Sides have one or two innings each, depending on the prearranged duration of the match, the object being to score the most runs. The bowlers, delivering the ball with a straight arm, try to break (hit) the wicket with the ball so that the bails fall. This is one of several ways that the batsman is dismissed, or put out. A bowler delivers six balls at one wicket (thus completing an “over”), then a different player from his side bowls six balls to the opposite wicket. The batting side defends its wicket.\"\n",
        "\n",
        "print(f\"Length of the passage: {len(passage.split())} words\")\n",
        "\n",
        "question1 = \"who play cricket\"\n",
        "_, _, _, _,ans = bert_question_answer(question1,passage)\n",
        "print(\"\\nAnswer from Bert: \",ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5delQOMXu7_",
        "outputId": "3f224433-446a-4ffa-8c72-55316b00aa2d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the passage: 205 words\n",
            "\n",
            "Answer from Bert:  england ’ s national summer sport , which is now played throughout the world , particularly in australia , india , pakistan , the west indies , and the british isles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#specify your file here, for question and answers\n",
        "with open(\"CricketData.txt\") as f:\n",
        "    passage = f.read()\n",
        "\n",
        "print(f\"Length of the passage: {len(passage.split())} words\")\n",
        "temp = True\n",
        "print(\"To Exit from QNA Please enter False \")\n",
        "while temp == True:\n",
        "    question1 = input(\"Enter your question: \")\n",
        "    if question1 == \"False\":\n",
        "        break\n",
        "    elif len(question1) > 2:\n",
        "        start_index, end_index, _, _,ans = bert_question_answer(question1,passage)\n",
        "        print(\"\\nAnswer from Bert: \",ans)\n",
        "        print(\"\\nStarting Index: \",start_index)\n",
        "        print(\"\\nEnding Index: \",end_index)\n",
        "    else:\n",
        "        print(\"please Enter proper question\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Rw_nfUR_ih",
        "outputId": "d52e357f-fdad-4a15-a795-62bbf9b8d103"
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of the passage: 415 words\n",
            "To Exit from QNA Please enter False \n",
            "Enter your question: howmuch wide is pitch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Answer from Bert:  3 . 04 metres )\n",
            "\n",
            "Starting Index:  93\n",
            "\n",
            "Ending Index:  97\n",
            "Enter your question: what is england nation summer sport\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Answer from Bert:  cricket\n",
            "\n",
            "Starting Index:  8\n",
            "\n",
            "Ending Index:  8\n",
            "Enter your question: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dpjOrnFycQvL"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}